---
title: Tensorflow Day8 CNN 解說 (1)
date: 2016-12-23 21:27:25
tags:
- tensorflow
- deeplearning
- ithome鐵人
---

 ## 今日目標

* 了解卷積神經網路流程
* 分析程式中的第一層卷積層訓練結果

<!--more-->

## CNN 流程

好的，我們現在已經成功了用 CNN 達到了非常不錯的準確率 (99.2%)，接下來就是來看一下到底它用了什麼樣的方法造成這麼厲害的結果，以及實現 CNN 的 Tensorflow 程式碼裡面的一些參數代表什麼意義？

在從網路中自學以後大概了解了 CNN 的用意，大概有以下三點:

1. **圖片中的特徵往往比整張圖片還要小**

   ex. 一張人臉照片中，幾個重要特徵會是眼睛，鼻子，耳朵．．．等．

2. **而圖片中的特徵常常是會重複出現的**

   ex. 一張人臉照片中，兩個眼睛特徵是非常相似的．

3. **要盡量的減少神經網路中的參數**

   ex. 如果輸入的圖片很大而且每個像素都連結到隱含層，這樣權重的數目會太多，導致計算困難．

那根據以上幾點我們回來看一下 CNN 的結構

![](http://imgur.com/bYFnDws.jpg)

圖片輸入會經過兩個卷積層 (convolutional layer) 然後把它扳平 (Flatten) 之後進入全連結層 (Fully Connected Layer) 最後就是進入 Softmax 分類成 10 個數字．

這些流程中的關鍵就是卷積層 (convolutional layer) ，卷積層的出現讓 CNN 可以達到上面的三個目標，接下來就讓我們一起看下去．

## 卷積層 Convolutional Layer

卷積層中有三個部分，我們會邊用邊用程式邊解說: 

* Convolution
* ReLU
* Max Pooling

![](http://imgur.com/2KE40Oo.jpg)



### Convolution

以下是建立 `convolution` 的五行程式碼: 

```python
def conv2d(x, W):
    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding = 'SAME')		(1)
x_image = tf.reshape(x, [-1, 28, 28, 1])									(2)
W_conv1 = weight_variable([5, 5, 1, 32])									(3)
b_conv1 = bias_variable([32])												(4)
result = conv2d(x_image, W_conv1) + b_conv1 								(5)
```

我們先從第二行開始看，它的用意是把圖片像素輸入變成一個 1x28x28x1 的四維矩陣．

* 第一個參數為 -1 的意思是不管輸入有幾個，Tensorflow 會自動調整的意思，假設輸入 50 個圖片第一個維度就是 50．
* 第二個第三個就是指數字圖片為 28 像素 x 28 像素 的意思
* 最後一個則是指色階，這裡又稱 **channel**，這裡因為我們的輸入都是黑白灰階，因此值為 1．如果是彩色圖有 RGB 三原色，這裡的數值就是 3．

第三行則是建立起過濾器 (filter)．過濾器我覺得也可以稱作特徵篩選器，可以想像說是負責來辨認圖片中的某些特徵，像是直線或是橫線或是轉彎處．

* 一二三維的數字 `[5, 5, 1]` 代表著這個過濾器是一個 5x5x1 的矩陣，這跟上面的圖片一樣 5x5 代表著 5 像素 x 5 像素，而 1 則代表著灰階．
* 最後一個數字 32 代表著我們建立了 32 個過濾器來篩選特徵．

第四行建立一個偏移值 (bias) 避免負數．

好的那現在讓我們先看一下經過訓練後前 16 個過濾器長得怎麼樣，其中紅色表示大於零的值，藍色表示小於零的值．

![](http://imgur.com/09eggaV.jpg)

接下來看到每個過濾器對應的輸出是如何 (result)

![](http://imgur.com/POlzyzX.jpg)

呃如果直接從圖片上面來看你看得出有什麼端倪嗎？

我們可以發現幾點

1. 如果過濾器中有藍色**橫線** (ex. 左下角) 那在輸出就會出現數字中有藍色**橫線**的地方
2. 如果過濾器中有藍色**斜線** (ex. 右上角) 那在輸出就會出現數字中有藍色**斜線**的地方

感覺這樣是不是每個過濾器所辨認到的 **特徵**都不一樣呢？

明天再讓我們繼續來看看過濾器是怎麼和資料發生互動的，以及經過 ReLU 的結果．



